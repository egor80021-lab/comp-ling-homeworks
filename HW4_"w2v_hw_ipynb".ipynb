{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В этом практикуме мы рассмотрим работу с библиотекой **Gensim** для работы с векторными представлениями текста\n",
        "\n",
        "Мы рассмотрим\n",
        "- **Word2Vec** - векторные представления слов\n",
        "- **FastText** - улучшенные представления с учетом морфологии  \n",
        "- **Doc2Vec** - векторные представления документов\n"
      ],
      "metadata": {
        "id": "N4SYal7iVHxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, FastText, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bolJ-w-oVVZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 1: Word2Vec\n",
        "\n",
        "### Что такое Word2Vec?\n",
        "\n",
        "Word2Vec преобразует слова в векторы чисел так, что семантически похожие слова оказываются близко в векторном пространстве.\n",
        "\n",
        "**Два основных алгоритма:**\n",
        "- **CBOW** - предсказывает слово по контексту\n",
        "- **Skip-gram** - предсказывает контекст по слову\n",
        "\n",
        "**Загрузка предобученной модели**"
      ],
      "metadata": {
        "id": "vB663h2uXJE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "print(f\"Размер словаря: {len(w2v_model.key_to_index)}\")\n",
        "print(f\"Размерность векторов: {w2v_model.vector_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "2m2YjiqkVVmd",
        "outputId": "77087cdd-435f-4e5e-ca52-e6ee22e6092b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1652775537.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove-wiki-gigaword-100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Размер словаря: {len(w2v_model.key_to_index)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Размерность векторов: {w2v_model.vector_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/gensim-data/glove-wiki-gigaword-100/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-wiki-gigaword-100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-wiki-gigaword-100.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m         \"\"\"\n\u001b[0;32m-> 1721\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1722\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2069\u001b[0m             )\n\u001b[1;32m   2070\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2071\u001b[0;31m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m         \u001b[0m_add_word_to_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_line_to_vector\u001b[0;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите документацию `gensim`: какие датасеты кроме `glove-wiki-gigaword-100` доступны в библиотеке?\n",
        "\n",
        "Выберите 3 датасета и кратко опишите их (источник данных, примерный объем, зачем такой датасет может использоваться)"
      ],
      "metadata": {
        "id": "VDOPbPZCXQJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Базовые операции с векторами**"
      ],
      "metadata": {
        "id": "eib9fIpIXp3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем вектор слова\n",
        "vector = w2v_model['computer']\n",
        "print(f\"Вектор слова 'computer': {vector[:5]}...\")  # Показываем первые 5 чисел\n",
        "\n",
        "# Вычисляем схожесть между словами\n",
        "similarity = w2v_model.similarity('computer', 'laptop')\n",
        "print(f\"Схожесть 'computer' и 'laptop': {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9fBjDYNXoUO",
        "outputId": "eb385a78-dcab-4746-ac67-35e0f84dac8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор слова 'computer': [-0.16298   0.30141   0.57978   0.066548  0.45835 ]...\n",
            "Схожесть 'computer' и 'laptop': 0.7024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Поиск похожих слов**"
      ],
      "metadata": {
        "id": "Ev1yMPZ8XuI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Находим похожие слова\n",
        "similar_words = w2v_model.most_similar('python', topn=5)\n",
        "print(\"Слова, похожие на 'python':\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"  {word}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "8WkxOy8uXteF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358d4d73-122e-48af-9922-0ccfc3065f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'python':\n",
            "  monty: 0.6886\n",
            "  php: 0.5865\n",
            "  perl: 0.5784\n",
            "  cleese: 0.5447\n",
            "  flipper: 0.5113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Ваш ответ здесь*"
      ],
      "metadata": {
        "id": "AKeYJM6IXgVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "1. Загрузите любой датасет из gensim на ваш выбор"
      ],
      "metadata": {
        "id": "TM76pHnKXi_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load(\"glove-wiki-gigaword-300\")\n",
        "\n",
        "print(f\"Размер словаря: {len(w2v_model.key_to_index)}\")\n",
        "print(f\"Размерность векторов: {w2v_model.vector_size}\")\n",
        "print(\"Пример слов:\", list(w2v_model.key_to_index.keys())[:10])"
      ],
      "metadata": {
        "id": "pqblXXpmXOhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcfca649-6684-4c22-d7e8-a9668e7a9609"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря: 400000\n",
            "Размерность векторов: 300\n",
            "Пример слов: ['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Напишите функцию, которая принимает на вход любое слово и вовращает 10 наиболее близких по вектору слов"
      ],
      "metadata": {
        "id": "vr2jwkoYXw4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ten_closest(word):\n",
        "    w = word.strip().lower()\n",
        "    if w not in w2v_model.key_to_index:\n",
        "        return \"Такого слова нет в словаре модели\"\n",
        "    return w2v_model.most_similar(w, topn=10)\n",
        "\n",
        "print(ten_closest(input(\"Введите слово: \")))"
      ],
      "metadata": {
        "id": "41PPnrrtX7lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec756c3-4e35-446b-ec78-2e096b0ba7cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите слово: girl\n",
            "[('boy', 0.8272891044616699), ('woman', 0.729641854763031), ('girls', 0.7227292060852051), ('teenager', 0.6509774327278137), ('teenage', 0.6492719054222107), ('mother', 0.6417974829673767), ('boys', 0.6283578872680664), ('child', 0.6229295134544373), ('teen', 0.612524151802063), ('daughter', 0.6050207614898682)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Обучите модель Word2Vec на тестовом датасете из ячейки ниже\n",
        "\n",
        "Примените следующие настройки:\n",
        "\n",
        "- размер вектора: 50\n",
        "- размер окна: 3\n",
        "- минимальная частота слова: 1\n",
        "- потоков: 2\n",
        "- использовать skip-gram"
      ],
      "metadata": {
        "id": "kqb9gAAtX-2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cooking_sentences = [\n",
        "    ['варить', 'суп', 'овощи', 'морковь', 'картофель'],\n",
        "    ['жарить', 'курица', 'сковорода', 'масло', 'специи'],\n",
        "    ['печь', 'хлеб', 'мука', 'дрожжи', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат', 'помидоры', 'огурцы'],\n",
        "    ['смешивать', 'ингредиенты', 'тесто', 'яйца', 'молоко'],\n",
        "    ['варить', 'паста', 'вода', 'соль', 'соус'],\n",
        "    ['гриль', 'мясо', 'овощи', 'уголь', 'барбекю'],\n",
        "    ['тушить', 'говядина', 'горшок', 'вино', 'травы'],\n",
        "    ['запекать', 'рыба', 'лимон', 'духовка', 'фольга'],\n",
        "    ['готовить', 'завтрак', 'яичница', 'бекон', 'тост'],\n",
        "    ['месить', 'тесто', 'пирог', 'начинка', 'яблоки'],\n",
        "    ['кипятить', 'вода', 'чай', 'кофе', 'чашка'],\n",
        "    ['мариновать', 'мясо', 'соус', 'специи', 'холодильник'],\n",
        "    ['взбивать', 'сливки', 'сахар', 'десерт', 'торт'],\n",
        "    ['парить', 'овощи', 'здоровое', 'питание', 'брокколи']\n",
        "]"
      ],
      "metadata": {
        "id": "Hx2_76jlX99p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Word2Vec(\n",
        "    sentences=cooking_sentences,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    sg=1\n",
        ")\n",
        "\n",
        "print(\"Готово! Модель обучена.\")\n",
        "print(\"Первые 10 слов в словаре:\", list(model.wv.key_to_index.keys())[:10])"
      ],
      "metadata": {
        "id": "-ql25a3lYIWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881b98f0-b917-4aa0-b7e1-48ebccd20853"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Готово! Модель обучена.\n",
            "Первые 10 слов в словаре: ['овощи', 'мясо', 'соус', 'вода', 'тесто', 'духовка', 'специи', 'варить', 'брокколи', 'питание']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Слова в словаре: {list(model.wv.key_to_index.keys())[:10]}...\")"
      ],
      "metadata": {
        "id": "uC6KfmGuYUsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea88119-fe1f-4f58-b219-67066a57beba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова в словаре: ['овощи', 'мясо', 'соус', 'вода', 'тесто', 'духовка', 'специи', 'варить', 'брокколи', 'питание']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Проверьте модель"
      ],
      "metadata": {
        "id": "rUp76Ko3YYLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем похожие слова в кулинарной тематике\n",
        "try:\n",
        "    similar = model.wv.most_similar('варить', topn=5)\n",
        "    print(\"Слова, похожие на 'варить':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'варить' не найдено в словаре\")"
      ],
      "metadata": {
        "id": "NL21ZMMMYZqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778be62b-0a05-46ff-fd58-3a7e9939674d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'варить':\n",
            "  вино: 0.2398\n",
            "  ингредиенты: 0.2172\n",
            "  хлеб: 0.1938\n",
            "  брокколи: 0.1846\n",
            "  кипятить: 0.1711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Найдите слова, похожие на \"духовка\"\n",
        "try:\n",
        "    similar = model.wv.most_similar('духовка', topn=10)\n",
        "    print(\"Слова, похожие на 'духовка':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'духовка' не найдено в словаре\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Найдите слова, похожие на \"овощи\"\n",
        "try:\n",
        "    similar = model.wv.most_similar('овощи', topn=10)\n",
        "    print(\"Слова, похожие на 'овощи':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'овощи' не найдено в словаре\")"
      ],
      "metadata": {
        "id": "DZWc7eNVYcSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdb0ce0-ddba-4c29-a290-0ffd5ac51d17"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'духовка':\n",
            "  ингредиенты: 0.3199\n",
            "  десерт: 0.3064\n",
            "  холодильник: 0.2705\n",
            "  питание: 0.2243\n",
            "  пирог: 0.2142\n",
            "  яблоки: 0.2049\n",
            "  парить: 0.1978\n",
            "  специи: 0.1834\n",
            "  вино: 0.1411\n",
            "  жарить: 0.1394\n",
            "\n",
            "Слова, похожие на 'овощи':\n",
            "  мариновать: 0.2716\n",
            "  хлеб: 0.2691\n",
            "  гриль: 0.2546\n",
            "  фольга: 0.2409\n",
            "  сахар: 0.2108\n",
            "  жарить: 0.1968\n",
            "  яблоки: 0.1862\n",
            "  говядина: 0.1759\n",
            "  парить: 0.1670\n",
            "  кипятить: 0.1610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 2: FastText"
      ],
      "metadata": {
        "id": "i1JAFNQvYhAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastText улучшает Word2Vec, рассматривая слова как наборы символов (n-грамм). Это позволяет работать с редкими словами и опечатками"
      ],
      "metadata": {
        "id": "Z1tWdzB-Ysi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Обучите FastText на корпусе текстов из пункта 3. Используйте код ниже"
      ],
      "metadata": {
        "id": "79i4vH8NY-0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = FastText(\n",
        "    sentences= cooking_sentences,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "-IrOgMpQYuda"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Найдите слова, похожие на \"варить\", \"духовка\" и \"овощи\" с помощью обученной модели. Используйте код из пункта 4"
      ],
      "metadata": {
        "id": "JBTW3zDPZIIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_similar_ft(word, topn=10):\n",
        "    try:\n",
        "        sims = ft_model.wv.most_similar(word, topn=topn)\n",
        "        print(f\"Слова, похожие на '{word}':\")\n",
        "        for w, score in sims:\n",
        "            print(f\"  {w}: {score:.4f}\")\n",
        "        print()\n",
        "    except KeyError:\n",
        "        print(f\"Слово '{word}' не найдено в словаре FastText\\n\")\n",
        "\n",
        "print_similar_ft(\"варить\", topn=10)\n",
        "print_similar_ft(\"духовка\", topn=10)\n",
        "print_similar_ft(\"овощи\", topn=10)"
      ],
      "metadata": {
        "id": "ouc0CcZAY6QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd51220-f5d6-45f3-e946-340294164321"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'варить':\n",
            "  жарить: 0.5353\n",
            "  парить: 0.4805\n",
            "  месить: 0.3541\n",
            "  тушить: 0.3405\n",
            "  специи: 0.2622\n",
            "  рыба: 0.2425\n",
            "  бекон: 0.2348\n",
            "  запекать: 0.2155\n",
            "  завтрак: 0.2032\n",
            "  смешивать: 0.1994\n",
            "\n",
            "Слова, похожие на 'духовка':\n",
            "  взбивать: 0.4565\n",
            "  лимон: 0.3561\n",
            "  салат: 0.3050\n",
            "  курица: 0.3041\n",
            "  тост: 0.2944\n",
            "  кофе: 0.2896\n",
            "  месить: 0.2676\n",
            "  говядина: 0.2456\n",
            "  масло: 0.2428\n",
            "  рыба: 0.2423\n",
            "\n",
            "Слова, похожие на 'овощи':\n",
            "  жарить: 0.2960\n",
            "  фольга: 0.2574\n",
            "  морковь: 0.2297\n",
            "  соус: 0.2172\n",
            "  торт: 0.2094\n",
            "  здоровое: 0.1955\n",
            "  ингредиенты: 0.1942\n",
            "  кипятить: 0.1651\n",
            "  сахар: 0.1448\n",
            "  барбекю: 0.1434\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Сравните модели\n",
        "\n",
        "Дана функция для сравнения Word2Vec и FastText\n",
        "\n",
        "Придумайте 3 слова с опечатками и проверьте, найдет ли их FastText и Word2Vec"
      ],
      "metadata": {
        "id": "vm8kkRlBZYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(word):\n",
        "    \"\"\"Сравнивает представления слова в разных моделях\"\"\"\n",
        "    print(f\"\\nСравнение для слова: '{word}'\")\n",
        "\n",
        "    # Word2Vec\n",
        "    try:\n",
        "        w2v_similar = model.wv.most_similar(word, topn=2)\n",
        "        print(f\"  Word2Vec: {[w for w, _ in w2v_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  Word2Vec: слово не найдено\")\n",
        "\n",
        "    # FastText\n",
        "    try:\n",
        "        ft_similar = ft_model.wv.most_similar(word, topn=2)\n",
        "        print(f\"  FastText: {[w for w, _ in ft_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText: слово не найдено\")\n",
        "\n",
        "# Сравниваем для разных слов\n",
        "compare_models('борбекю')\n",
        "compare_models('сус')"
      ],
      "metadata": {
        "id": "3nVH_v9WZY4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66361271-c1cf-4520-c2d3-7f44598fcccb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сравнение для слова: 'борбекю'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['барбекю', 'говядина']\n",
            "\n",
            "Сравнение для слова: 'сус'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['лимон', 'фольга']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 3: Doc2Vec"
      ],
      "metadata": {
        "id": "DP62ewZzZoGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec расширяет Word2Vec для создания векторных представлений целых документов (предложений, абзацев, статей)"
      ],
      "metadata": {
        "id": "tG1GNzXcZqOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем размеченные документы\n",
        "documents = [\n",
        "    \"machine learning is interesting\",\n",
        "    \"deep learning uses neural networks\",\n",
        "    \"python programming for data science\",\n",
        "    \"artificial intelligence is amazing\",\n",
        "    \"computer vision processes images\"\n",
        "]\n",
        "\n",
        "# Преобразуем в формат TaggedDocument\n",
        "tagged_docs = []\n",
        "for i, doc in enumerate(documents):\n",
        "    tokens = doc.split()\n",
        "    tagged_doc = TaggedDocument(words=tokens, tags=[f\"doc_{i}\"])\n",
        "    tagged_docs.append(tagged_doc)\n",
        "\n",
        "print(\"Размеченные документы:\")\n",
        "for doc in tagged_docs[:3]:\n",
        "    print(f\"  Слова: {doc.words}\")\n",
        "    print(f\"  Тег: {doc.tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_85mtFa_ZxoY",
        "outputId": "094f8233-4161-484c-9385-f57d20104691"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеченные документы:\n",
            "  Слова: ['machine', 'learning', 'is', 'interesting']\n",
            "  Тег: ['doc_0']\n",
            "  Слова: ['deep', 'learning', 'uses', 'neural', 'networks']\n",
            "  Тег: ['doc_1']\n",
            "  Слова: ['python', 'programming', 'for', 'data', 'science']\n",
            "  Тег: ['doc_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем Doc2Vec\n",
        "doc_model = Doc2Vec(\n",
        "    documents=tagged_docs,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "print(\"Doc2Vec модель обучена!\")\n",
        "print(f\"Количество документов: {len(doc_model.dv.key_to_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJ1vOcHZx0z",
        "outputId": "5721c106-8fe8-4744-8440-fa0d9857e3bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc2Vec модель обучена!\n",
            "Количество документов: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем вектор документа\n",
        "doc_vector = doc_model.dv[\"doc_0\"]\n",
        "print(f\"Вектор документа doc_0: {doc_vector[:5]}...\")\n",
        "\n",
        "# Находим похожие документы\n",
        "similar_docs = doc_model.dv.most_similar(\"doc_0\", topn=2)\n",
        "print(\"\\nДокументы, похожие на doc_0:\")\n",
        "for doc_tag, similarity in similar_docs:\n",
        "    doc_id = int(doc_tag.split('_')[1])\n",
        "    print(f\"  {doc_tag}: {similarity:.4f}\")\n",
        "    print(f\"    Текст: {documents[doc_id]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x8vHn0bZ0Ow",
        "outputId": "f12ab016-6811-4840-b13b-2a87bd8d528e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор документа doc_0: [-0.01057    -0.01198188 -0.01982618  0.01710627  0.00710373]...\n",
            "\n",
            "Документы, похожие на doc_0:\n",
            "  doc_1: 0.2735\n",
            "    Текст: deep learning uses neural networks\n",
            "  doc_2: 0.1275\n",
            "    Текст: python programming for data science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравниваем схожесть документов\n",
        "def compare_documents(doc1_id, doc2_id):\n",
        "    similarity = doc_model.dv.similarity(f\"doc_{doc1_id}\", f\"doc_{doc2_id}\")\n",
        "    print(f\"Схожесть doc_{doc1_id} и doc_{doc2_id}: {similarity:.4f}\")\n",
        "    print(f\"  doc_{doc1_id}: {documents[doc1_id]}\")\n",
        "    print(f\"  doc_{doc2_id}: {documents[doc2_id]}\")\n",
        "\n",
        "compare_documents(0, 1)  # machine learning vs deep learning\n",
        "compare_documents(0, 3)  # machine learning vs AI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfjR2xZZ1rC",
        "outputId": "21917c5d-1945-4206-f41a-dd17d06e5426"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_0 и doc_1: 0.2735\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_1: deep learning uses neural networks\n",
            "Схожесть doc_0 и doc_3: -0.0822\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_3: artificial intelligence is amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Сравните схожесть doc_2 и doc_4"
      ],
      "metadata": {
        "id": "1ruGP7-vZ6HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_documents(2, 4)"
      ],
      "metadata": {
        "id": "LujlVE8aZ3fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd6032d-6d51-498a-d9e3-f9da4788d5c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_2 и doc_4: -0.0362\n",
            "  doc_2: python programming for data science\n",
            "  doc_4: computer vision processes images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Найдите самый похожий документ на doc_1"
      ],
      "metadata": {
        "id": "YkW4U8T_Z_X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ids = range(len(documents))\n",
        "max_similarity = -1\n",
        "most_similar_doc = None\n",
        "\n",
        "for i in doc_ids:\n",
        "    if i == 1:\n",
        "        continue\n",
        "    sim = compare_documents(1, i)\n",
        "    if sim > max_similarity:\n",
        "        max_similarity = sim\n",
        "        most_similar_doc = i\n",
        "\n",
        "print(f\"\\nНаиболее похожий документ на doc_1 — doc_{most_similar_doc}, similarity: {max_similarity:.4f}\")\n",
        "print(\"Текст doc_1:\", documents[1])\n",
        "print(f\"Текст doc_{most_similar_doc}:\", documents[most_similar_doc])"
      ],
      "metadata": {
        "id": "T0IwRpOPaGX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a69102-8ce5-40b9-e50f-74c9cd5a58f6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_1 и doc_0: 0.2735\n",
            "  doc_1: 1\n",
            "  doc_0: 0\n",
            "Схожесть doc_1 и doc_2: -0.0573\n",
            "  doc_1: 1\n",
            "  doc_2: 2\n",
            "Схожесть doc_1 и doc_3: 0.2031\n",
            "  doc_1: 1\n",
            "  doc_3: 3\n",
            "Схожесть doc_1 и doc_4: -0.2546\n",
            "  doc_1: 1\n",
            "  doc_4: 4\n",
            "\n",
            "Наиболее похожий документ на doc_1 — doc_0, similarity: 0.2735\n",
            "Текст doc_1: 1\n",
            "Текст doc_0: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Выберите любую из трёх моделей. Обучите модели с разной размерностью (10, 50, 100). Продемонстрируйте качество их работы на примере поиска похожих слов (выберите любые 3 примера, соответствующих тематике корпуса из пункта 4)"
      ],
      "metadata": {
        "id": "GHoOQmGraGmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "sizes = [10, 50, 100]\n",
        "test_words = [\"варить\", \"духовка\", \"овощи\"]\n",
        "\n",
        "models_by_size = {}\n",
        "\n",
        "for sz in sizes:\n",
        "    m = Word2Vec(\n",
        "        sentences=cooking_sentences,\n",
        "        vector_size=sz,\n",
        "        window=3,\n",
        "        min_count=1,\n",
        "        workers=2,\n",
        "        sg=1\n",
        "    )\n",
        "    models_by_size[sz] = m\n",
        "    print(f\" Обучили Word2Vec: vector_size={sz}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "for word in test_words:\n",
        "    print(f\"\\nСлово: '{word}'\")\n",
        "    for sz in sizes:\n",
        "        m = models_by_size[sz]\n",
        "        try:\n",
        "            sims = m.wv.most_similar(word, topn=5)\n",
        "            sims_words = [w for w, _ in sims]\n",
        "            print(f\"  size={sz}: {sims_words}\")\n",
        "        except KeyError:\n",
        "            print(f\"  size={sz}: слова нет в словаре\")"
      ],
      "metadata": {
        "id": "tidpF7AIaXzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78dece6-97f8-4a90-886b-15e01aba95be"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Обучили Word2Vec: vector_size=10\n",
            " Обучили Word2Vec: vector_size=50\n",
            " Обучили Word2Vec: vector_size=100\n",
            "\n",
            "============================================================\n",
            "\n",
            "Слово: 'варить'\n",
            "  size=10: ['рыба', 'сковорода', 'хлеб', 'готовить', 'яичница']\n",
            "  size=50: ['вино', 'ингредиенты', 'хлеб', 'брокколи', 'кипятить']\n",
            "  size=100: ['чашка', 'вино', 'сковорода', 'суп', 'мука']\n",
            "\n",
            "Слово: 'духовка'\n",
            "  size=10: ['взбивать', 'тушить', 'говядина', 'кипятить', 'лимон']\n",
            "  size=50: ['ингредиенты', 'десерт', 'холодильник', 'питание', 'пирог']\n",
            "  size=100: ['жарить', 'парить', 'завтрак', 'тесто', 'вода']\n",
            "\n",
            "Слово: 'овощи'\n",
            "  size=10: ['жарить', 'фольга', 'горшок', 'уголь', 'ингредиенты']\n",
            "  size=50: ['мариновать', 'хлеб', 'гриль', 'фольга', 'сахар']\n",
            "  size=100: ['взбивать', 'питание', 'бекон', 'резать', 'гриль']\n"
          ]
        }
      ]
    }
  ]
}